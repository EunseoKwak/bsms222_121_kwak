---
title: "R Notebook"
output: html_notebook
---

# Chapter 9 visualizing data distributions

numerical data is often summarized with the _average_ value / standard deviation
Is it appropriate?

we'll learn how to summarize lists of factors or numerical vectors
'data visualization'
the most basic summary of a list of objects or numers - distribution

# 9.1 Variable Types

categorical and numeric variables; categorical can be ordinal or not, numerical variables can be discrete or continuous

when each entry in a vector comes from one of a small numbers of groups; _categorical data_
ex) sex, regions
can be orders even when not numerical : _ordinal data_
ex) spiciness

numerical data
ex) population sizes, murder rates, heights
some numerical data an be treated as ordered categorical
_continuous variables_ : that can take any value
_discrete variables_ : have to be round numbers

__Discrete numeric data an be considred ordinal__

there are examples that can be considered both numerical and ordinal when it comes to visualizing data

# 9.2 case study: describing student heights

Pretend that we have to describe the heights of our classmate to ETㅋㅋㅋㅋ
we ask heights in inches, sex information

```{r}
library(tidyverse)
library(dslabs)
data(heights)
head(heights)
```

there are much more effective ways to convey this information more than SIMPLY SENDING THE LIST

# 9.3 Distribution function

In some cases, the average and the standard deviation are all we need.
we'll learn data visualization techniques that will help us determine if this two number summary is appropriate.

The most basic summary; distribution
with categorical data; the distribution describes the proportion of each category.
The sex represented;

#> 
#> Female   Male 
#>  0.227  0.773

this two-category frequency table is the simples form of a distribution. We don't even have to visualize!
when there are more categories, we can make a simple barplot: shows each categoy and numbers for each
although does not provide much more insight than a frequency table itself, it is a first example of how we convert a vector into a plot that summarizes all the information in the vector. For numeric data, displaying is more challenging

# 9.4 Cumulative distribution functions

numeric data that are not categorical; reporting the frequency of each entry is not effective - all unique entries!

a more useful way to define a distribution for numeric data : define a function that reports the proportion of data below a for all possible values of a; __cumulative distribution funciton(CDF)__

we can report the proportion of values between any two heights

because cdfs can be defined mathematically, we use the term __empirical cdf(eCDF)__

# 9.5 Histograms

the CDF plot is actually not very popular in practice : does not convey characteristics of interest (Ex. At what value is the distribution centered? Is the distribution symmetric? What range contain 95% of the values?) -> Histograms are much preferred

1. Divide the span of our data into non-overlapping bins of the same size
2. For each bin, we count the number of values that fall in that interval

similar to barplot, but differs in that the x-axis is numerical, not categorical

1. range of majority(more than 95%) is known
2. can see if the distribution is symmetric
3. can get approximatino of the proportion of the data in any interval

what do we lose?
1. We cannot distinguish numbers in the same interval(ex. 64, 64.1)

# 9.6 Smoothed Density

Smooth density plots are aesthetically more appealing than histograms

1. we no longer have sharp edges at the interval boundaries and many of the local peacks are removed
2. The scale of the y-axis change from counts to _density_

_estimates_ -> we assume that our list of observed values is a subset of much larger list of unobserved values, and the larger distribution is what we want to report to ET since it is much more general. 

-> We make an assumption that helps us approximate it. We make a histogram with very, very small bins

The smooth desntiy; the curve that goes through the top of the higoram bars whne the bins are very, very small. We compute the curve on frequencies

In reality, we therefore make a histogram, using bin sizes appropriate for our data and computing frequencies rather than counts, draw a smooth curve

but 'smooth' is a relative term
We can control 'smoothness' of the curve through an option in the function

# 9.6.1 Interpreting the y-axis

Interpreting the y-axis of a smooth density plot is not straightforward.
We can use different size intervals -> the best way to determine the proportion of data in that interval : computing the proportion of the total area

# 9.6.2 Densities permit stratification

advantage of smooth densities over histograms for visualization is that densities make it easier to compare two distributions -> jagged edges of the histogram add clutter

ggplot automatically shades the intersecting region with a different color

# 9.7 Exercises

1. In the murders dataset, the region is a categorical variable and the following is its distribution:

To the closet 5%, what proportion of the states are in the North Central region?

+ to the closest 5?

__25%__

2. Which of the following is true:

A. The graph above is a histogram.

__B. The graph above shows only four numbers with a bar plot.__

C. Categories are not numbers, so it does not make sense to graph the distribution.

D. The colors, not the height of the bars, describe the distribution.

3. The plot below shows the eCDF for male heights:

https://rafalab.github.io/dsbook/book_files/figure-html/ecdf-exercise-1.png

Based on the plot, what percentage of males are shorter than 75 inches?

A. 100%

__B. 95%__

C. 80%

D. 72 inches

4. To the closest inch, what height m has the property that 1/2 of the male students are taller than m and 1/2 are shorter?

A. 61 inches

B. 64 inches

__C. 69 inches__

D. 74 inches

5. Here is an eCDF of the murder rates across states:

https://rafalab.github.io/dsbook/book_files/figure-html/ecdf-exercise-2-1.png

Knowing that there are 51 states (counting DC) and based on this plot, how many states have murder rates larger than 10 per 100,000 people?

__A. 1__

B. 5

C. 10

D. 50

+ 0.25/2/6*51

6. Based on the eCDF above, which of the following statements are true:

A. About half the states have murder rates above 7 per 100,000 and the other half below.

B. Most states have murder rates below 2 per 100,000.

C. All the states have murder rates above 2 per 100,000.

__D. With the exception of 4 states, the murder rates are below 5 per 100,000.__

7. Below is a histogram of male heights in our heights dataset:

https://rafalab.github.io/dsbook/book_files/figure-html/height-histogram-exercise-1.png

Based on this plot, how many males are between 63.5 and 65.5?

A. 10

B. 24

__C. 34__

D. 100

+ 11+33

8. About what percentage are shorter than 60 inches?

__A. 1%__

B. 10%

C. 25%

D. 50%

```{r}
15*100/812
```

+ 1과 2가 같이 있었으면 구하지 못했을 것 같다. count estimate 잘하려면 어떡하징

9. Based on the density plot below, about what proportion of US states have populations larger than 10 million?

https://rafalab.github.io/dsbook/book_files/figure-html/density-exercise-1.png

A. 0.02

__B. 0.15__

C. 0.50

D. 0.55

10. Below are three density plots. Is it possible that they are from the same dataset?

https://rafalab.github.io/dsbook/book_files/figure-html/density-exercise-2-1.png

Which of the following statements is true:

A. It is impossible that they are from the same dataset.

B. They are from the same dataset, but the plots are different due to code errors.

C. They are the same dataset, but the first and second plot undersmooth and the third oversmooths.

__D. They are the same dataset, but the first is not in the log scale, the second undersmooths and the third oversmooths.__

# 9.8 The normal distribution

Normal distribution(bell curve, Gaussian distribution) : widely used. Occur in many situations

the normal distribution is defined with a mathematical formula

it is completely defined by just two parameters: m(average) and s(standard deviation).
the rest of the symbols in a formula represent the interval ends and known mathematical constants

the distribution is symmetric, and most values(95%) are within 2 SDs from the average

if a dataset is approximated by a normal distribution, all the information can be encoded in just two numers; average, SD

```{r}
m <- sum(x) / length(x)
```

```{r}
s <- sqrt(sum((x-mu)^2) / length(x))
```

```{r}
index <- heights$sex=="Male"
x <- heights$height[index]
```

sd divides by _length(x)-1_ rather than _length(x)_ can be used here

```{r}
m <- mean(x)
s <- sd(x)
c(average = m, sd = s)
```

# 9.9 Standard units

The standard unit of a value tells us how many standard deviations away from the average it is.

for a value x from a vector X, we define the value of x in standard units as z=(x-m)/s
why is it convenient?

1. In the formula, -z^2/2 with z equivalent to x in standard units - maximum of e^(-z^2/2) is when z=0. Maximum of distribution occurs at the average, and symmetric around 0.

2. if we convert the normally distributed data to standard units, we can quickly know if: a person is about average(z=0), one of the largest(z about 2), extremely rare occurence(z>3, z<-3)

we can obtain Standard Units using function 'scale'

```{r}
z <- scale(x)
```

```{r}
mean(abs(z) < 2)
```

# 9.10 Quantile-quantile plots

A systematic way to assess how well the normal distribution fits the data is to check if the observed and predicted proportions match.

-> approach of the qqplot

we use functino 'pnorm' to give the probability of a standard normal distribution being smaller than x

```{r}
pnorm(-1.96)
```

The inverse function gives us the _theoretical quantiles_ for the normal distribution
we can evaulate the inverse using the function 'qnorm'

```{r}
qnorm(0.975)
```

these calculations are for standard normal distribution by default(m=0, SD=1)
we can also define for all distribution using arguments 'mean', 'sd'

```{r}
qnorm(0.975, mean = 5, sd = 2)
```

all the calculations related to quantiles are done without data, thus the name theoretical quantiles.

quantiles can be defined for any distribution: any proportion p as the q for which the proportion of values below q is p 'mean(x<=0)=p'

not all p have a q

```{r}
mean(x <= 69.5)
```

about 50% are shorter or equal to 69 inches.

The idea of a QQ-plot is that if your data is well approximated by normal distribution then the quantiles of your data should be similar to the quantiles of a normal distribution.

1. define a vector of m proportions
2. define a vector of quantiles for your data for the proportions : _Sample quantiles_
3. define a vector of theoretical quantiles for the proportions for a normal distribution with the same average and SD
4. plot the sample quantiles versus the theoretical quantiles


```{r}
p <- seq(0.05, 0.95, 0.05)
```

function 'quantile'

```{r}
sample_quantiles <- quantile(x, p)
sample_quantiles
```

to obtain theoretical normal distribution quantiles; 'qnorm' function

```{r}
theoretical_quantiles <- qnorm(p, mean = mean(x), sd = sd(x))
```

```{r}
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
```

this codes become cleaner if we use Standard Units

```{r}
sample_quantiles <- quantile(z, p)
theoretical_quantiles <- qnorm(p) 
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
```

it is easier to use ggplot2 code

```{r}
library(ggplot2)
heights %>% filter(sex=="Male") %>%
  ggplot(aes(sample = scale(height))) + 
  geom_qq() +
  geom_abline()
```

While for the illustration above we used 20 quantiles, the default from the geom_qq function is to use as many quantiles as data points.

# 9.11 Percentiles

Percentiles are special cases of quantiles that are commonly used.

the case of p=0.25, the 25th percentile, which gives us a number for which 25% of the data is below.

For the normal distribution the median and average are the same, but this is generally not the case.

Another special case that receives a name are the quartiles, which are obtained when setting p=0.25, 0.50, 0.75

# 9.12 Boxplots

A more compact numerical summary

provide a five number summary(quartiles), ignore outliers, plot these as independent points, 'box offered by 25% and 75% percentile' with whiskers. distance btwn two : Interquartile range. two points; outliers, median - horizontal line

we can see the median, symmetric, range, outlier

# 9.13 Stratification

we often divide observations into groups based on the values of one or more variables associated with those observations : _stratification_, resulting groups: _strata_

# 9.14 Case study: describing student heights

We learned that boxplots are useful when we want to quickly compare two or more distributions. Here are the heights for men and women:

https://rafalab.github.io/dsbook/book_files/figure-html/female-male-boxplots-1.png

males are, on average, taller than females. Standard deviation appears to be similar.

For female distribution, We see something we did not see for the males: the density plot has a second “bump”

Also, the QQ-plot shows that the highest points tend to be taller than expected by the normal distribution, and five points are shorter than expected heights

perhaps, explanation is that in the form students used to enter their heights, FEMALE was the default sex and some males entered their heights, but forgot to change the sex variable.

five smallest values;
```{r}
heights %>% filter(sex=="Female") %>% top_n(5, desc(height)) %>% pull(height)
```

# 9.15 Exercises

1. Define variables containing the heights of males and females like this:

```{r}
library(dslabs)
data(heights)
male <- heights$height[heights$sex=="Male"]
female <- heights$height[heights$sex=="Female"]
```

How many measurements do we have for each?

```{r}
length(male)
length(female)
```

2. Suppose we can’t make a plot and want to compare the distributions side by side. We can’t just list all the numbers. Instead, we will look at the percentiles. Create a five row table showing female_percentiles and male_percentiles with the 10th, 30th, 50th, …, 90th percentiles for each sex. Then create a data frame with these two as columns.

```{r}
female_percentiles <- quantile(female, seq(0.1, 0.9, 0.2))
male_percentiles <- quantile(male, seq(0.1, 0.9, 0.2))

height_sex_percentiles <- data.frame(female_percentiles, male_percentiles)

height_sex_percentiles
```

3. Study the following boxplots showing population sizes by country:

https://rafalab.github.io/dsbook/book_files/figure-html/boxplot-exercise-1.png

Which continent has the country with the biggest population size?

_Asia_
whisker 끝

4. what continent has the largest median population size?

_Africa_ 
boxplot 안의 선

5. What is median population size for Africa to the nearest million?

_10 million_
y axis의 값

6. What proportion of countries in Europe have populations below 14 million?

A. 0.99

__B. 0.75__

C. 0.50

D. 0.25

_The box defined by the 25% and 75% percentile_

7. If we use a log transformation, which continent shown above has the largest interquartile range?

```{r}
log(550000000)-log(150000)
log(1300000000)-log(660000)
```

_Americas_

8. Load the height data set and create a vector x with just the male heights:

```{r}
library(dslabs)
data(heights)
x <- heights$height[heights$sex=="Male"]
```

What proportion of the data is between 69 and 72 inches (taller than 69, but shorter or equal to 72)? Hint: use a logical operator and mean.

```{r}
mean(x>69 & x<=72)
```

9. Suppose all you know about the data is the average and the standard deviation. Use the normal approximation to estimate the proportion you just calculated. Hint: start by computing the average and standard deviation. Then use the pnorm function to predict the proportions.

```{r}
average <- mean(x)
sd <- sd(x)
pnorm(72,average, sd)- pnorm(69, average, sd)
  
```

10. Notice that the approximation calculated in question two is very close to the exact calculation in the first question. Now perform the same task for more extreme values. Compare the exact calculation and the normal approximation for the interval (79,81]. How many times bigger is the actual proportion than the approximation?

```{r}
exactcal <- mean(x>79 & x<=81)
normalapp <- pnorm(81, average, sd) - pnorm(79, average, sd)
exactcal/normalapp
```

11. Approximate the distribution of adult men in the world as normally distributed with an average of 69 inches and a standard deviation of 3 inches. Using this approximation, estimate the proportion of adult men that are 7 feet tall or taller, referred to as seven footers. Hint: use the pnorm function.

```{r}
# 1 feet = 12 inches
1 - pnorm(84, 69, 3)
```

12. There are about 1 billion men between the ages of 18 and 40 in the world. Use your answer to the previous question to estimate how many of these men (18-40 year olds) are seven feet tall or taller in the world?

```{r}
10^9 * (1 - pnorm(84, 69, 3))
```

13. There are about 10 National Basketball Association (NBA) players that are 7 feet tall or higher. Using the answer to the previous two questions, what proportion of the world’s 18 to 40 year old seven footers are in the NBA?

```{r}
sevenfooter <- 10^9 * (1 - pnorm(84, 69, 3))
10/sevenfooter
```

14. Repeat the calculations performed in the previous question for Lebron James’ height: 6 feet 8 inches. There are about 150 players that are at least that tall.

```{r}
six_ft_8_inch <- 10^9*(1-pnorm(6*12+8, 69, 3))
150/six_ft_8_inch
```

15. In answering the previous questions, we found that it is not at all rare for a seven footer to become an NBA player. What would be a fair critique of our calculations:

A. Practice and talent are what make a great basketball player, not height.

B. The normal approximation is not appropriate for heights.

__C. As seen in question 3, the normal approximation tends to underestimate the extreme values. It’s possible that there are more seven footers than we predicted.__

D. As seen in question 3, the normal approximation tends to overestimate the extreme values. It’s possible that there are less seven footers than we predicted.

# 9.16 Ggplot2 geometries

we introduced the ggplot2 package for data visualization.

# 9.16.1 Barplots

'geom_bar' geometry: default is to count the number of each category and draw a bar

```{r}
murders %>% ggplot(aes(region)) + geom_bar()
```

table with a distribution:

```{r}
data(murders)
tab <- murders %>% 
  count(region) %>% 
  mutate(proportion = n/sum(n))
tab
```

we no longer want 'geom_bar' to count, but rather just plot a bar to the height provided by the 'proportion' variable
we need to provide x(categories), y(values) and use the option 'stat=identity' option

```{r}
tab %>% ggplot(aes(region, proportion)) + geom_bar(stat = "identity")
```

# 9.16.2 Histograms
we use 'geom_histogram'
the only required argument is x.

```{r}
heights %>% 
  filter(sex == "Female") %>% 
  ggplot(aes(height)) + 
  geom_histogram()
```

bin size of 1:

```{r}
heights %>% 
  filter(sex == "Female") %>% 
  ggplot(aes(height)) + 
  geom_histogram(binwidth = 1)
```

for aesthetic regions we want to add color and a title:

```{r}
heights %>% 
  filter(sex == "Female") %>% 
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1, fill = "blue", col = "black") +
  xlab("Male heights in inches") + 
  ggtitle("Histogram")
```

# 9.16.3 Density plots

geom_density

```{r}
heights %>% 
  filter(sex == "Female") %>%
  ggplot(aes(height)) +
  geom_density()
```

too fill in with color, argument 'fill':

```{r}
heights %>% 
  filter(sex == "Female") %>%
  ggplot(aes(height)) +
  geom_density(fill="blue")
```

+) I prefer violet

```{r}
heights %>% 
  filter(sex == "Female") %>%
  ggplot(aes(height)) +
  geom_density(fill="violet")
```

to change the smoothness of density
, we use argument' adjust' to multiply default value

```{r}
heights %>% 
  filter(sex == "Female") %>% ggplot(aes(height)) +
  geom_density(fill="blue", adjust = 2)
```

+ 일해라 introduction to data science

# 9.16.4 Boxplots

geom_boxplot
we need argument x as the categories, y as the values

# 9.16.5 Qqplots

geom_qq
we need to specify the sample

```{r}
heights %>% filter(sex=="Male") %>%
  ggplot(aes(sample = height)) +
  geom_qq()
```

By default, the sample variable is compared to average 0, SD 1 normal distribution

we use arguments 'dparams' to change this
for straight lines, we use the 'geom_abline' function, and the default line is slope=1, intercept=0

```{r}
params <- heights %>% filter(sex=="Male") %>%
  summarize(mean = mean(height), sd = sd(height))

heights %>% filter(sex=="Male") %>%
  ggplot(aes(sample = height)) +
  geom_qq(dparams = params) +
  geom_abline()
```

another option here is to scale the data first and then make a qqplot against the standard normal

```{r}
heights %>% 
  filter(sex=="Male") %>%
  ggplot(aes(sample = scale(height))) + 
  geom_qq() +
  geom_abline()
```

# 9.1.6 Images

geom_tile, geom_raster
we use a dataframe with x and y coordinates as well as the value associated with each of these

```{r}
x <- expand.grid(x = 1:12, y = 1:10) %>% 
  mutate(z = 1:120) 
```

this is the tidy version of a matrix(1:120, 12, 10)

```{r}
x %>% ggplot(aes(x, y, fill = z)) + 
  geom_raster()
```

layer 'scale_fill_gradientn' layer : change the color scale

```{r}
x %>% ggplot(aes(x, y, fill = z)) + 
  geom_raster() + 
  scale_fill_gradientn(colors =  terrain.colors(10))
```

# 9.16.7 Quick plots

we can also use qplot to make histograms, density plots, boxplot, qqplots, not only scatterplots

to make a quick histogram:

```{r}
x <- heights %>% 
  filter(sex=="Male") %>% 
  pull(height)
qplot(x)
```

guesses that we want to make a histogram because we only supplied one variable. If apply two variables : scatterplot

you have to use the argument 'sample' to make a quick qqplot

```{r}
qplot(sample = scale(x)) + geom_abline()
```

If we supply a factor and a numeric vector, we obtain a plot like the below. Note that in the code below we are using the data argument. using dot operators ; data frame is not the first argument in qplot

```{r}
heights %>% qplot(sex, height, data = .)
```

We can also select a specific geometry by using the geom argument.

```{r}
heights %>% qplot(sex, height, data = ., geom = "boxplot")
```

```{r}
qplot(x, geom = "density")
```

we do have some flexibility to improve the results of qplot

```{r}
qplot(x, bins=15, color = I("black"), xlab = "Population")
```

__The reason we use I("black") is because we want qplot to treat "black" as a character rather than convert it to a factor, which is the default behavior within aes, which is internally called here. In general, the function I is used in R to say “keep it as it is”.__

# 9.17 Exercises

1. Now we are going to use the geom_histogram function to make a histogram of the heights in the height data frame. When reading the documentation for this function we see that it requires just one mapping, the values to be used for the histogram. Make a histogram of all the plots.

What is the variable containing the heights?

A. sex

B. heights

C. height

__D. heights$height__

2. Now create a ggplot object using the pipe to assign the heights data to a ggplot object. Assign height to the x values through the aes function.

```{r}
heights  %>% 
  ggplot(aes(height))
```

3. Now we are ready to add a layer to actually make the histogram. Use the object created in the previous exercise and the geom_histogram function to make the histogram.

```{r}
heights %>% 
  ggplot(aes(height)) + geom_histogram()
```

4. Note that when we run the code in the previous exercise we get the warning: stat_bin() using bins = 30. Pick better value with binwidth. Use the binwidth argument to change the histogram made in the previous exercise to use bins of size 1 inch.

```{r}
heights %>% 
  ggplot(aes(height)) + geom_histogram(binwidth=1)
```

5. Instead of a histogram, we are going to make a smooth density plot. In this case we will not make an object, but instead render the plot with one line of code. Change the geometry in the code previously used to make a smooth density instead of a histogram.

```{r}
heights %>% 
  ggplot(aes(height)) + geom_density()
```

6. Now we are going to make a density plot for males and females separately. We can do this using the group argument. We assign groups via the aesthetic mapping as each point needs to a group before making the calculations needed to estimate a density.

```{r}
heights %>% 
  ggplot(aes(height)) + geom_density(aes(group=sex))
```

7. We can also assign groups through the color argument. This has the added benefit that it uses color to distinguish the groups. Change the code above to use color

```{r}
heights %>% 
  ggplot(aes(height)) + geom_density(aes(color=sex))
```

8. We can also assign groups through the fill argument. This has the added benefit that it uses colors to distinguish the groups, like this:

```{r}
heights %>% 
  ggplot(aes(height, fill = sex)) + 
  geom_density() 
```

However, here the second density is drawn over the other. We can make the curves more visible by using alpha blending to add transparency. Set the alpha parameter to 0.2 in the geom_density function to make this change.

```{r}
heights %>% 
  ggplot(aes(height, fill = sex)) + 
  geom_density(alpha=0.2) 
```