---
title: "R Notebook"
output: html_notebook
---

## 15.6 Confidence intervals

Confidence intervals are a very useful concept widely employed by data analysts. A version of these that are commonly seen come from the ggplot geometry geom_smooth.

Shaded area around the curve: created using the concept of confidence intervals.

We need to be balanced between having small interval and including p in the interval.

We want to know the probability that the interval [$\bar{X}$-2$\hat{SE(\bar{X})}$, $\bar{X}$+2$\hat{SE(\bar{X})}$] contains the true proportion p.

start and end of this intervals are random variables

```{r}
p <- 0.45
N <- 1000
```

```{r}
x <- sample(c(0, 1), size = N, replace = TRUE, prob = c(1-p, p))
x_hat <- mean(x)
se_hat <- sqrt(x_hat * (1 - x_hat) / N)
c(x_hat - 1.96 * se_hat, x_hat + 1.96 * se_hat)
```

is different from this one

```{r}
x <- sample(c(0,1), size=N, replace=TRUE, prob=c(1-p, p))
x_hat <- mean(x)
se_hat <- sqrt(x_hat * (1 - x_hat) / N)
c(x_hat - 1.96 * se_hat, x_hat + 1.96 * se_hat)
```

-> Random variation

so we have

$$
Pr(-1.96 <= Z <= 1.96)
$$
which can be computed

```{r}
pnorm(1.96)-pnorm(-1.96)
```

we have a 95% probability.

For 99% probability:

```{r}
z <- qnorm(0.995)
z
```

```{r}
pnorm(z) - pnorm(-z)
```

we set z=qnorm(1-(1-p)/2) because 1-(1-p)/2+(1-p)/2=p

```{r}
qnorm(0.975)
```

### 15.6.1 A Monte Carlo Simulation

We can run a monte carlo simulation to confirm that a 95% confidence interval includes p 95% of the time

```{r}
N <- 1000
B <- 10000
inside <- replicate(B, {
  x <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
  x_hat <- mean(x)
  se_hat <- sqrt(x_hat * (1 - x_hat) / N)
  between(p, x_hat - 1.96 * se_hat, x_hat + 1.96 * se_hat)
})
mean(inside)
```

### 15.6.2 The correct language

Remember that it is the intervals that are random, not p.

## 15.7 Exercises

```{r}
library(dslabs)
data("polls_us_election_2016")
```

```{r}
library(tidyverse)
polls <- polls_us_election_2016 %>% 
  filter(enddate >= "2016-10-31" & state == "U.S.") 
```

1. For the first poll, you can obtain the samples size and estimated Clinton percentage with:

```{r}
N <- polls$samplesize[1]
x_hat <- polls$rawpoll_clinton[1]/100
```

Assume there are only two candidates and construct a 95% confidence interval for the election night proportion p.

```{r}
se_hat <- sqrt(x_hat * (1-x_hat) / N)
c(x_hat-1.96 * se_hat, x_hat+1.96 * se_hat)
```

2. Now use dplyr to add a confidence interval as two columns, call them lower and upper, to the object poll. Then use select to show the pollster, enddate, x_hat,lower, upper variables. Hint: define temporary columns x_hat and se_hat.

```{r}
polls %>% mutate(x_hat = polls$rawpoll_clinton/100, se_hat = sqrt(x_hat*(1-x_hat)/samplesize),
                 lower = x_hat - 1.96*se_hat, upper = x_hat + 1.96*se_hat) %>%
  select(pollster, enddate, x_hat, lower, upper)
```

3. The final tally for the popular vote was Clinton 48.2% and Trump 46.1%. Add a column, call it hit, to the previous table stating if the confidence interval included the true proportion p=0.482 or not. 

```{r}
polls %>% mutate(x_hat = polls$rawpoll_clinton/100, se_hat = sqrt(x_hat*(1-x_hat)/samplesize),
                 lower = x_hat - 1.96*se_hat, upper = x_hat + 1.96*se_hat) %>%
  select(pollster, enddate, x_hat, lower, upper) %>% mutate(hit=lower<=0.482 & upper>=0.482) 
```

4. For the table you just created, what proportion of confidence intervals included p?

```{r}
polls %>% mutate(x_hat = polls$rawpoll_clinton/100, se_hat = sqrt(x_hat*(1-x_hat)/N),
                 lower = x_hat - 1.96*se_hat, upper = x_hat + 1.96*se_hat) %>%
  select(pollster, enddate, x_hat, lower, upper) %>% mutate(hit=lower<=0.482 & upper>=0.482) %>% summarize(mean(hit))
```

5. If these confidence intervals are constructed correctly, and the theory holds up, what proportion should include p?

__0.95__

6. A much smaller proportion of the polls than expected produce confidence intervals containing p. If you look closely at the table, you will see that most polls that fail to include p are underestimating. The reason for this is undecided voters, individuals polled that do not yet know who they will vote for or do not want to say. Because, historically, undecideds divide evenly between the two main candidates on election day, it is more informative to estimate the spread or the difference between the proportion of two candidates d, which in this election was 0.482−0.461=0.021. Assume that there are only two parties and that d=2p−1, redefine polls as below and re-do exercise 1, but for the difference.

```{r}
polls <- polls_us_election_2016 %>% 
  filter(enddate >= "2016-10-31" & state == "U.S.")  %>%
  mutate(d_hat = rawpoll_clinton / 100 - rawpoll_trump / 100)
```

```{r}
N <- polls$samplesize[1]
d_hat <- polls$d_hat[1]
x_hat <- (d_hat+1)/2
se_hat <- 2*sqrt(x_hat*(1-x_hat)/N)
c(d_hat-1.96 * se_hat, d_hat+1.96 * se_hat)
```

7. Now repeat exercise 3, but for the difference.

```{r}
polls %>% mutate(X_hat = (d_hat+1)/2, se_hat = 2*sqrt(X_hat*(1-X_hat)/samplesize), lower = d_hat-1.96*se_hat, upper = d_hat + 1.96*se_hat) %>% select(pollster, enddate, d_hat, lower, upper) %>% mutate(hit = lower<=0.021 & upper>=0.021)
```

8. Now repeat exercise 4, but for the difference.

```{r}
polls %>% mutate(X_hat = (d_hat+1)/2, se_hat = 2*sqrt(X_hat*(1-X_hat)/samplesize), lower = d_hat - 1.96*se_hat, upper = d_hat+1.96*se_hat) %>% select(pollster, enddate, d_hat, lower, upper) %>% mutate(hit = lower<=0.021 & upper>=0.021) %>% summarize(mean(hit))
```

9. Although the proportion of confidence intervals goes up substantially, it is still lower than 0.95. In the next chapter, we learn the reason for this. To motivate this, make a plot of the error, the difference between each poll’s estimate and the actual d=0.021. Stratify by pollster.

```{r}
polls %>% mutate(error = d_hat - 0.021) %>% 
  ggplot(aes(pollster, error)) +
  geom_point()
```

10. Redo the plot that you made for exercise 9, but only for pollsters that took five or more polls.

```{r}
polls %>% mutate(error = d_hat - 0.021) %>%
  group_by(pollster) %>%
  filter(n() >= 5) %>%
  ggplot(aes(pollster, error)) +
  geom_point()
```

## 15.8 Power

When we took a 25 bead sample size, the confidence interval for the spread:

```{r}
N <- 25
x_hat <- 0.48
(2 * x_hat - 1) + c(-1.96, 1.96) * 2 * sqrt(x_hat * (1 - x_hat) / N)
```

includes 0.

Given the sample size and the value of p, we would have to sacrifice on the probability of an incorrect call to create an interval that does not include 0.

Increasing sample size; lower se and have much better chance of detecting the direction of the spread

## 15.9 P-values

I want to know if the spread 2p-1>0.
N=100, we observe 52 blue beads, 2Xbar-1=0.04.

the p-value is the answer to the question: how likely is it to see a value this large, when the null hypothesis is true? 

```{r}
N <- 100
z <- sqrt(N)*0.02/0.5
1 - (pnorm(z) - pnorm(-z))
```

there is actually a large chance of seeing 52 or larger under the null hypothesis.

If a 95% confidence interval of the spread does not include 0, we know that the p-value must be smaller than 0.05.

## 15.10 Association tests

```{r}
library(tidyverse)
library(dslabs)
data("research_funding_rates")
research_funding_rates %>% select(discipline, applications_total, 
                                  success_rates_total) %>% head()
```

```{r}
names(research_funding_rates)
```

```{r}
totals <- research_funding_rates %>% 
  select(-discipline) %>% 
  summarize_all(sum) %>%
  summarize(yes_men = awards_men, 
            no_men = applications_men - awards_men, 
            yes_women = awards_women, 
            no_women = applications_women - awards_women) 
```

larger percent of men than woman received awards:
```{r}
totals %>% summarize(percent_men = yes_men/(yes_men+no_men),
                     percent_women = yes_women/(yes_women+no_women))
```

## 15.10.1 Lady Tasting tea

An acquaintance of Fisher’s claimed that she could tell if milk was added before or after tea was poured.
The null hypothesis here is that she is guessing.
Fisher derived the distribution for the number of correct picks on the assumption that the choices were random and independent.

The basic question we ask is: if the tester is actually guessing, what are the chances that she gets 3 or more correct?

The chance of observing a 3 or something more extreme, under the null hypothesis, is ≈0.24.

## 15.10.2 Two-by-two tables

```{r}
tab <- matrix(c(3,1,1,3),2,2)
rownames(tab)<-c("Poured Before","Poured After")
colnames(tab)<-c("Guessed before","Guessed after")
tab
```

function 'fisher.test' : inference calculation above:

```{r}
fisher.test(tab, alternative="greater")$p.value
```

### 15.10.3 Chi-square test

```{r}
totals %>% summarize(percent_men = yes_men/(yes_men+no_men),
                     percent_women = yes_women/(yes_women+no_women))
```

```{r}
rate <- totals %>%
  summarize(percent_total = 
              (yes_men + yes_women)/
              (yes_men + no_men +yes_women + no_women)) %>%
  pull(percent_total)
rate
```

create 2-by-2 table

```{r}
two_by_two <- data.frame(awarded = c("no", "yes"), 
                     men = c(totals$no_men, totals$yes_men),
                     women = c(totals$no_women, totals$yes_women))
two_by_two
```

compare table to what you expect to see

```{r}
data.frame(awarded = c("no", "yes"), 
       men = (totals$no_men + totals$yes_men) * c(1 - rate, rate),
       women = (totals$no_women + totals$yes_women) * c(1 - rate, rate))
```

We can see that more men than expected and fewer women than expected received funding. 

under null hypothesis; random variable.s

The Chi-square test tells us how likely it is to see a deviation this large or larger. This test uses an asymptotic result, similar to the CLT, related to the sums of independent binary outcomes. The R function chisq.test takes a two-by-two table and returns the results from the test:

```{r}
chisq_test <- two_by_two %>% select(-awarded) %>% chisq.test()
chisq_test$p.value
```

## 15.10.4 The odds ratio

The odds of getting funded if you are a man is:

```{r}
odds_men <- with(two_by_two, (men[2]/sum(men)) / (men[1]/sum(men)))
odds_men
```

And the odds of being funded if you are a woman is:

```{r}
odds_women <- with(two_by_two, (women[2]/sum(women)) / (women[1]/sum(women)))
odds_women
```

### 15.10.5 Confidence intervals for the odds ratio

Not mathematically straightforward.

Confidence interval:

```{r}
log_or <- log(odds_men / odds_women)
se <- two_by_two %>% select(-awarded) %>%
  summarize(se = sqrt(sum(1/men) + sum(1/women))) %>%
  pull(se)
ci <- log_or + c(-1,1) * qnorm(0.975) * se
```

back to odds ratio scale, exponentiate:

```{r}
exp(ci)
```

1 is not included; p-value<0.05

```{r}
2*(1 - pnorm(log_or, 0, se))
```

This is a slightly different p-value than that with the Chi-square test. This is because we are using a different asymptotic approximation to the null distribution.

### 15.10.6 Small count correction

Note that the log odds ratio is not defined if any of the cells of the two-by-two table is 0. For this situation, it is common practice to avoid 0s by adding 0.5 to each cell. Haldane-Anscombe correction.

### 15.10.7 Large samples, small p-values

Reporting only p-values is not an appropriate way to report the results of data analysis.

Note that the relationship between odds ratio and p-value is not one-to-one. It depends on the sample size. So a very small p-value does not necessarily mean a very large odds ratio. 

multiply table by 10, doesn't change odds ratio:

```{r}
two_by_two %>% select(-awarded) %>%
  mutate(men = men*10, women = women*10) %>%
  chisq.test() %>% .$p.value
```

## 15.11 Exercises

1. A famous athlete has an impressive career, winning 70% of her 500 career matches. However, this athlete gets criticized because in important events, such as the Olympics, she has a losing record of 8 wins and 9 losses. Perform a Chi-square test to determine if this losing record can be simply due to chance as opposed to not performing well under pressure.

```{r}
two_by_two <- data.frame(results = c("wins", "losses"), 
                     important_events = c(8, 9),
                     not_important_events = c(350-8, 150-9))
two_by_two
chisq_test <- two_by_two %>% select(-results) %>% chisq.test()
chisq_test$p.value
```

2. Why did we use the Chi-square test instead of Fisher’s exact test in the previous exercise?

A. It actually does not matter, since they give the exact same p-value.
B. Fisher’s exact and the Chi-square are different names for the same test.
__C. Because the sum of the rows and columns of the two-by-two table are not fixed so      the hypergeometric distribution is not an appropriate assumption for the null         hypothesis. For this reason, Fisher’s exact test is rarely applicable with observational data.__
D. Because the Chi-square test runs faster.!

3. Compute the odds ratio of “losing under pressure” along with a confidence interval.

```{r}
odds_important_events <- with(two_by_two, (important_events[1]/sum(important_events)) / (important_events[2]/sum(important_events)))
odds_not_important_events <- with(two_by_two, (not_important_events[1]/sum(not_important_events)) / (not_important_events[2]/sum(not_important_events)))
log_or <- log(odds_important_events / odds_not_important_events)
se <- two_by_two %>% select(-results) %>%
  summarize(se = sqrt(sum(1/important_events) + sum(1/not_important_events))) %>%
  pull(se)
ci <- log_or + c(-1,1) * qnorm(0.975) * se
exp(ci)
```

4. Notice that the p-value is larger than 0.05 but the 95% confidence interval does not include 1. What explains this?

A. We made a mistake in our code.
B. These are not t-tests so the connection between p-value and confidence intervals      does not apply.
__C. Different approximations are used for the p-value and the confidence interval         calculation. If we had a larger sample size the match would be better.__
D. We should use the Fisher exact test to get confidence intervals.

5. Multiply the two-by-two table by 2 and see if the p-value and confidence retrieval are a better match.

```{r}
two_by_two %>% select(-results) %>%
  mutate(important_events = important_events*10, not_important_events = not_important_events*10) %>%
  chisq.test() %>% .$p.value
```