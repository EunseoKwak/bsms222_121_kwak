---
title: "R Notebook"
output: html_notebook
---

## 14.7  Central Limit Theorem
The Central Limit Theorem (CLT) tells that when the number of draws, also called the sample size, is large, the probability distribution of the sum of the independent draws is approximately normal.

```{r}
n <- 1000
B <- 10000
roulette_winnings <- function(n){
  X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
  sum(X)
}
S <- replicate(B, roulette_winnings(n))
```

The Central Limit Theorem (CLT) tells us that the sum \(S\) is approximated by a normal distribution.

E(X) and SE(X)
```{r}
n * (20-18)/38 
sqrt(n) * 2 * sqrt(90)/19 
```

theoretical value match

```{r}
mean(S)
sd(S)
```

```{r}
mu <- n * (20-18)/38
se <-  sqrt(n) * 2 * sqrt(90)/19 
pnorm(0, mu, se)
```

```{r}
mean(S < 0)
```

### 14.7.1  How large is large in the Central Limit Theorem?

Large is a relative term. In many circumstances as few as 30 draws is enough to make the CLT useful.

When the probability of a success is very low: the Poisson distribution is more appropriate.

function 'dpois', 'ppois', generate varaibles using 'rpois'

## 14.8 Statistical properties of averages

1. The expected value of the sum of random variables is the sum of each random variable’s expected value.

2. The expected value of a non-random constant times a random variable is the non-random constant times the expected value of a random variable.

3. The square of the standard error of the sum of independent random variables is the sum of the square of the standard error of each random variable. 

4. The standard error of a non-random constant times a random variable is the non-random constant times the random variable’s standard error.

5. If X is a normally distributed random variable, then if a and b are non-random constants, aX+b is also a normally distributed random variable. All we are doing is changing the units of the random variable by multiplying by a then shifting the center by b.

## 14.9 Law of large numbers

the standard error of the average becomes smaller and smaller as n grows larger

### 14.9.1 Misinterpreting law of averages

The law of averages applies only when the number of draws is very large and not in small samples.

## 14.10 Exercises


1. In American Roulette you can also bet on green. There are 18 reds, 18 blacks and 2 greens (0 and 00). What are the chances the green comes out?

```{r}
2/(18+18+2)
```

2. The payout for winning on green is 17 dollars. This means that if you bet a dollar and it lands on green, you get 17. Create a sampling model using sample to simulate the random variable X for your winnings. Hint: see the example below for how it should look like when betting on red.

```{r}
x <- sample(c(1,-1), 1, prob = c(9/19, 10/19))
```

```{r}
x2 <- sample(c(17,-1),1, prob = c(2/38, 36/38))
```

3. Compute the expected value of X.
```{r}
2/38 * 17 + 36/38 * -1
```

4. Compute the standard error of X.
```{r}
abs((17 - -1))*sqrt(2/38*36/38)
```

5. Now create a random variable S hat is the sum of your winnings after betting on green 1000 times. Hint: change the argument `size` and `replace` in your answer to question 2. Start your code by setting the seed to 1 with `set.seed(1)`.

```{r}
set.seed(1)
B <- 1000
greeeen <- sample(c(17,-1), B, replace=TRUE, prob = c(2/38, 36/38))
S <- sum(greeeen)
S
```

6. What is the expected value of S?

```{r}
B * (2/38 * 17 + 36/38 * -1)
```

7. What is the standard error of S?

```{r}
sqrt(B) * abs((17 - -1))*sqrt(2/38*36/38)
```

8. What is the probability that you end up winning money? Hint: use the CLT.

```{r}
m <- B * (2/38 * 17 + 36/38 * -1)
se <- sqrt(B) * abs((17 - -1))*sqrt(2/38*36/38)
1 - pnorm(0, m, se)
```

9. Create a Monte Carlo simulation that generates 1,000 outcomes of S. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with set.seed(1).

```{r}
set.seed(1)
listoutcome <- replicate(B,{
  X <- sample(c(17,-1), B, replace=TRUE, prob = c(2/38, 36/38))
  sum(X)
})
mean(listoutcome)
sd(listoutcome)
```

10. Now check your answer to 8 using the Monte Carlo result.
```{r}
mean(listoutcome>0)
```

11. The Monte Carlo result and the CLT approximation are close, but not that close. What could account for this?

A. 1,000 simulations is not enough. If we do more, they match.  
__B. The CLT does not work as well when the probability of success is small. In this case, it was 1/19. If we make the number of roulette plays bigger, they will match better.__
C. The difference is within rounding error.  
D. The CLT only works for averages.  

12. Now create a random variable Y that is your average winnings per bet after playing off your winnings after betting on green 1,000 times.

```{r}
X <- sample(c(17,-1), 1000, replace=TRUE, prob = c(2/38, 36/38))
Y <- mean(X)
```

13. What is the expected value of Y?

```{r}
1000 * (2/38 * 17 + 36/38 * -1)
```


14. What is the standard error of Y?

```{r}
sqrt(1000)*abs((17 - -1))*sqrt(2/38*36/38)
```

15. What is the probability that you end up with winnings per game that are positive? Hint: use the CLT.

```{r}
m <- 1000 * (2/38 * 17 + 36/38 * -1)
se <- sqrt(1000)*abs((17 - -1))*sqrt(2/38*36/38)
1 - pnorm(0, m, se)
```

16. Create a Monte Carlo simulation that generates 2,500 outcomes of Y. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with `set.seed(1)`.

```{r}
set.seed(1)
listoutcome2 <- replicate(2500,{
  Y <- sample(c(17,-1), 1000, replace=TRUE, prob = c(2/38, 36/38))
  mean(Y)
})
mean(listoutcome2)
sd(listoutcome2)
```

17. Now check your answer to 8 using the Monte Carlo result.

```{r}
mean(listoutcome2>0)
```

18. The Monte Carlo result and the CLT approximation are now much closer. What could account for this?

A. We are now computing averages instead of sums.  
B. 2,500 Monte Carlo simulations is not better than 1,000.  
__C. The CLT works better when the sample size is larger. We increased from 1,000 to 2,500.__
D. It is not closer. The difference is within rounding error.

## 14.11 Case study ; The big short

### 14.11.1 Interest rates explained with chance model

You run a bank.
Only 2% of your customers default, meaning that they don’t pay back the money that you lent them. 

Suppose your bank will give out 1,000 loans for $180,000 this year. Also, after adding up all costs, suppose your bank loses $200,000 per foreclosure. For simplicity, we assume this includes all operational costs. A sampling model for this scenario can be coded like this:

```{r}
n <- 1000
loss_per_foreclosure <- -200000
p <- 0.02 
defaults <- sample( c(0,1), n, prob=c(1-p, p), replace = TRUE)
sum(defaults * loss_per_foreclosure)
#> [1] -5400000
```

```{r}
B <- 10000
losses <- replicate(B, {
    defaults <- sample( c(0,1), n, prob=c(1-p, p), replace = TRUE) 
  sum(defaults * loss_per_foreclosure)
})
```

the CLT tells us that because our losses are a sum of independent draws, its distribution is approximately normal

```{r}
n*(p*loss_per_foreclosure + (1-p)*0)
sqrt(n)*abs(loss_per_foreclosure)*sqrt(p*(1-p))
```

```{r}
- loss_per_foreclosure*p/(1-p)
```

Although this interest rate guarantees that on average we break even, there is a 50% chance that we lose money. If our bank loses money, we have to close it down. We therefore need to pick an interest rate that makes it unlikely for this to happen.

We add and subtract the same quantities to both sides of the event  S<0 so that the probability does not change and we end up with a standard normal random variable on the left, which will then permit us to write down an equation with only x as an unknown.

```{r}
qnorm(0.01)
```

```{r}
l <- loss_per_foreclosure
z <- qnorm(0.01)
x <- -l*( n*p - z*sqrt(n*p*(1-p)))/ ( n*(1-p) + z*sqrt(n*p*(1-p)))
x
```

```{r}
loss_per_foreclosure*p + x*(1-p)
```

```{r}
n*(loss_per_foreclosure*p + x*(1-p)) 
```

```{r}
B <- 100000
profit <- replicate(B, {
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-p, p), replace = TRUE) 
    sum(draws)
})
mean(profit)
mean(profit<0)
```

### 14.11.2 The big short

Even if the default rate is twice as high, say 4%, if we set the rate just a bit higher than this value:

```{r}
p <- 0.04
r <- (- loss_per_foreclosure*p/(1-p)) / 180000
r
```

we will profit. At 5%, we are guaranteed a positive expected value of:

```{r}
r <- 0.05
x <- r*180000
loss_per_foreclosure*p + x * (1-p)
```

and can minimize our chances of losing money 

with Z a standard normal random variable as shown earlier. If we define mu and sigma to be the expected value and standard deviation of the urn, respectively (that is of a single loan), using the formulas above we have: E[S] = nmu and SE[S] = sqrt{n}sigma. 

 as long as mu is positive, we can find an n that minimizes the probability of a loss. This is a form of the law of large numbers: when n is large, our average earnings per loan converges to the expected earning mu.

With x fixed, now we can ask what n do we need for the probability to be 0.01? In our example, if we give out:

```{r}
z <- qnorm(0.01)
n <- ceiling((z^2*(x-l)^2*p*(1-p))/(l*p + x*(1-p))^2)
n
```

loans, the probability of losing is about 0.01 and we are expected to earn a total of

```{r}
n*(loss_per_foreclosure*p + x * (1-p))
```

```{r}
p <- 0.04
x <- 0.05*180000
profit <- replicate(B, {
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-p, p), replace = TRUE) 
    sum(draws)
})
mean(profit)
```

This seems like a no brainer. As a result, your colleague decides to leave your bank and start his own high-risk mortgage company. A few months later, your colleague’s bank has gone bankrupt. A book is written and eventually a movie is made relating the mistake your friend, and many others, made. What happened?

By making n large, we minimize the standard error of our per-loan profit. However, for this rule to hold, the Xs must be independent draws

To construct a more realistic simulation than the original one your colleague ran, let’s assume there is a global event that affects everybody with high-risk mortgages and changes their probability. We will assume that with 50-50 chance, all the probabilities go up or down slightly to somewhere between 0.03 and 0.05. But it happens to everybody at once, not just one person. These draws are no longer independent.

```{r}
p <- 0.04
x <- 0.05*180000
profit <- replicate(B, {
    new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-new_p, new_p), replace = TRUE) 
    sum(draws)
})
```

our expected profit is still large:

```{r}
mean(profit)
```

However, the probability of the bank having negative earnings shoots up to:

```{r}
mean(profit<0)
```

Even scarier is that the probability of losing more than 10 million dollars is:

```{r}
mean(profit < -10000000)
```

To understand how this happens look at the distribution:

```{r}
data.frame(profit_in_millions=profit/10^6) %>% 
  ggplot(aes(profit_in_millions)) + 
  geom_histogram(color="black", binwidth = 5)
```

The theory completely breaks down and the random variable has much more variability than expected.

## 14.12 Exercises

1. Create a random variable S with the earnings of your bank if you give out 10,000 loans, the defalut rate is 0.3, and you lose $200,000 in each foreclosure. Hint: use the code we showed in the previous section, but change the parameters.

```{r}
n <- 10000
loss_per_foreclosure <- -200000
rate <- 0.03
loans <- sample(c(0,1), n, replace = TRUE, prob=c(1-rate, rate))
S <- sum(loans * loss_per_foreclosure)
S
```

2. Run a Monte Carlo simulation with 10,000 outcomes for $S$. Make a histogram of the results.

```{r}
sim <- replicate(n, {
  loans <- sample(c(0,1), n, replace = TRUE, prob=c(1-rate, rate))
  sum(loans * loss_per_foreclosure)
})
hist(sim)
```

3. What is the expected value of S?

```{r}
n*(rate*loss_per_foreclosure + (1-rate)*0)
```

4. What is the standard error of S?

```{r}
sqrt(n) * abs(loss_per_foreclosure) * sqrt(rate*(1-rate))
```

5. Suppose we give out loans for $180,000. What should the interest rate be so that our expected value is 0?

```{r}
x <- -(loss_per_foreclosure*rate) / (1 - rate)
x / 180000
```

6. What should the interest rate be so that the chance of losing money is 1 in 20? In math notation, what should the interest rate be so that Pr(S < 0) = 0.05?

```{r}
z <- qnorm(0.05)
x <- -loss_per_foreclosure*( n*rate - z*sqrt(n*rate*(1-rate)))/ ( n*(1-rate) + z*sqrt(n*rate*(1 -rate)))
x / 180000
```

7. If the bank wants to minimize the probabilities of losing money, which of the following does not make interest rates go up?

A. A smaller pool of loans.  
B. A larger probability of default.  
C. A smaller required probability of losing money.  
__D. The number of Monte Carlo simulations.__